---
layout: workshop
year: 2025
date: April 2025
location: ICLR 2025 in Singapore
openreview: https://openreview.net/group?id=ICLR.cc/2025/Workshop/Re-Align
show_cfp: true

cover_image:
  image: "/assets/images/locations/singapore.jpg"
  author: Brandon Lim
  licence_name: "CC BY-SA 2.0"
  licence_link: "https://creativecommons.org/licenses/by-sa/2.0/"

buttons:
  - text: OpenReview
    url: https://openreview.net/group?id=ICLR.cc/2025/Workshop/Re-Align
  - text: ICLR.cc
    url: https://iclr.cc/Conferences/2025

important_dates:
  - event: Paper submission deadline
    date: Monday, February 3rd, 2025
  - event: Reviewing deadline
    date: Friday, February 21st, 2025
  - event: Author notification
    date: Monday, March 3rd, 2025
  - event: Camera-ready copy (CRC) deadline
    date: Sunday, April 20th, 2025

speakers:
  - name: Phil Isola
    affiliation: MIT
    website: https://web.mit.edu/phillipi/
    image: profile_isola.jpeg
  - name: Janet Wiles
    affiliation: University of Queensland
    website: https://eecs.uq.edu.au/profile/2444/janet-wiles
    image: profile_wiles.jpg
  - name: Alex Williams
    affiliation: NYU
    website: https://neurostatslab.org/
    image: profile_williams.jpg

organizers:
  - name: Brian Cheung
    affiliation: MIT
    website: https://briancheung.github.io/
    image: brian.jpg
  - name: Dota Dong
    affiliation: MPI for Psycholinguistics
    website: https://tianaidong.github.io/
    image: dota.jpg
  - name: Erin Grant
    affiliation: UCL
    website: https://eringrant.github.io/
    image: erin.jpeg
  - name: Ilia Sucholutsky
    affiliation: NYU
    website: https://ilia10000.github.io/
    image: ilia.jpeg
  - name: Lukas Muttenthaler
    affiliation: TU Berlin
    website: https://lukasmut.github.io/
    image: lukas.jpeg
  - name: Siddharth Suresh
    affiliation: University of Wisconsin-Madison
    website: https://www.sidsuresh.com/
    image: sid.jpg

news:
  - content: The <a class="scroll-link" href="#cfp">call for contributed papers</a> at Re-Align 2025 is now live!
  - content: The 2025 edition of Re-Align was accepted as a workshop at ICLR 2025!

about: |
  Both natural and artificial intelligences form representations of the world that they use to reason, make decisions,
  and communicate. Despite extensive research across machine learning, neuroscience, and cognitive science, it
  remains unclear what the most appropriate ways are to compare and align the representations of intelligent systems
  ([Sucholutsky et al., 2023](https://arxiv.org/abs/2310.13018)). 
  In the second edition of the Workshop on Representational Alignment (Re-Align), we
  bring together researchers from diverse fields who study representational alignment to make concrete progress on
  this set of open interdisciplinary problems. We invite researchers across the machine learning, neuroscience, and
  cognitive science communities to participate in the workshop, and to contribute to the workshop in two ways:

  **First, in the form of [contributed papers](#cfp)** that
  address questions of representational alignment that stem from the following central theme: When and why 
  do intelligence systems learn aligned representations, and how can scientists and engineers intervene on this alignment? 
  Other questions topical for this yearâ€™s workshop include:
  - To what extent does representational alignment indicate shared computational strategies among biological and artificial systems?
  - How have current alignment metrics advanced our understanding of computation, and what measurement approaches should we explore next?
  - How can we develop more robust and generalizable measures of alignment that work across different domains and types of representations?
  - How can we systematically increase (or decrease) representational alignment among biological and artificial systems?
  - What are the implications (positive and negative) of increasing or decreasing representational alignment between systems, on behavioral alignment, value alignment, and beyond?

  **Second, by participating in our workshop [hackathon](#hackathon)**.
  Since the first iteration of Re-Align workshop, there have been numerous debates around the metrics that
  we use to measure representational similarity, which is often taken as a measure of representational alignment (e.g.,
  [Cloos et al., 2024](https://arxiv.org/abs/2407.07059); 
  [Khosla et al., 2024](https://doi.org/10.1101/2024.06.20.599957); 
  [Lampinen et al., 2024](https://arxiv.org/abs/2405.05847); 
  [Schaeffer et al., 2024](https://openreview.net/forum?id=vbtj05J68r)). 
  As of now, there is little consensus on which metric best achieves the goal of identifying similarity
  between systems.
  The hackathon component of the workshop will be helpful in articulating the consequences of these methodologies
  by facilitating a common language among researchers, and as a result increase the reproducibility of research in this
  subdomain.

hackathon: |
  *Details coming soon!*
---
